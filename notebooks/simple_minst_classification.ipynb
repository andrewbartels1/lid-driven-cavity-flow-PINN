{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN MNIST.ipynb\n",
    "Automatically generated by Colaboratory.\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/14YB2h3vxvxOanJc1yDDEqw0O4atiz7Rm\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed_all(2)\n",
    "\n",
    "\n",
    "def im_convert(tensor):\n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    return image\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, kernel_size=5, stride=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # 2x2 maxpool\n",
    "        self.fc1 = nn.Linear(4 * 4 * 10, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # 24x24x10\n",
    "        x = self.pool(x)  # 12x12x10\n",
    "        x = F.relu(self.conv2(x))  # 8x8x10\n",
    "        x = self.pool(x)  # 4x4x10\n",
    "        x = x.view(-1, 4 * 4 * 10)  # flattening\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST(\n",
    "    \"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]),\n",
    ")\n",
    "batch_size = 100\n",
    "validation_split = 0.1\n",
    "shuffle_dataset = True\n",
    "random_seed = 2\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_ds)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "valid_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, sampler=train_sampler\n",
    ")\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=batch_size, sampler=valid_sampler\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor()]),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_errors = []\n",
    "train_acc = []\n",
    "val_errors = []\n",
    "val_acc = []\n",
    "n_train = len(train_loader) * batch_size\n",
    "n_val = len(validation_loader) * batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    c = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        print('this is output', output, type(output))\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc += torch.sum(torch.max(output, dim=1)[1] == labels).item() * 1.0\n",
    "        c += 1\n",
    "\n",
    "    # validation\n",
    "\n",
    "    total_loss_val = 0\n",
    "    total_acc_val = 0\n",
    "    c = 0\n",
    "    for images, labels in validation_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        total_loss_val += loss.item()\n",
    "        total_acc_val += torch.sum(torch.max(output, dim=1)[1] == labels).item() * 1.0\n",
    "        c += 1\n",
    "\n",
    "    train_errors.append(total_loss / n_train)\n",
    "    train_acc.append(total_acc / n_train)\n",
    "    val_errors.append(total_loss_val / n_val)\n",
    "    val_acc.append(total_acc_val / n_val)\n",
    "\n",
    "print(\"Trainig complete\")\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax[0].plot(train_errors, \"r\", label=\"Train\")\n",
    "ax[0].plot(val_errors, \"g\", label=\"Validation\")\n",
    "ax[0].set_title(\"Grafik error\")\n",
    "ax[0].set_ylabel(\"Error (cross-entropy)\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_acc, \"r\", label=\"Train\")\n",
    "ax[1].plot(val_acc, \"g\", label=\"Validation\")\n",
    "ax[1].set_title(\"Grafik akurasi\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "total_acc = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    output = model(images)\n",
    "    total_acc += torch.sum(torch.max(output, dim=1)[1] == labels).item() * 1.0\n",
    "\n",
    "print(\"Test accuracy :\", total_acc / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lid_driven_cavity_flow_pin)",
   "language": "python",
   "name": "lid_driven_cavity_flow_pin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
